import express from 'express';
import type { Request, Response, NextFunction } from 'express';
import { OpenAIBackend } from './backends/openai';
import { GeminiBackend } from './backends/gemini';
import { LLMBackend } from './backends/base';
import type { Message, ModelMap } from './types';
import { AxiosError } from 'axios';
import { handleGenerate } from './handlers/generate';
import { handleChat } from './handlers/chat';
import { 
  handleListModels, 
  handleModelOperation, 
  handleModelCopy, 
  handleModelDelete,
  handleModelTags,  // è¿½åŠ 
  handleModelShow   // è¿½åŠ 
} from './handlers/models';

const app = express();
app.use(express.json());

// ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ‡ãƒãƒƒã‚°ç”¨ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
app.use((req: Request, res: Response, next: NextFunction) => {
  // undefinedã®å ´åˆã¯ç©ºã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰±ã†
  const safeBody = req.body || {};
  console.log('ğŸ“¨ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡:', {
    method: req.method,
    path: req.path,
    query: req.query,
    body: JSON.parse(JSON.stringify(safeBody)),
    headers: req.headers
  });
  next();
});

// ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‡ãƒãƒƒã‚°ç”¨ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
app.use((req: Request, res: Response, next: NextFunction) => {
  const originalJson = res.json;
  res.json = function(body) {
    // undefinedã®å ´åˆã¯ç©ºã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰±ã†
    const safeBody = body || {};
    console.log('ğŸ“¤ ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€ä¿¡:', {
      method: req.method,
      path: req.path,
      statusCode: res.statusCode,
      body: JSON.parse(JSON.stringify(safeBody))
    });
    return originalJson.call(this, body);
  };
  next();
});

// â”€â”€ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ– â”€â”€
const backends: Record<string, LLMBackend> = {
  openai: new OpenAIBackend(process.env.OPENAI_API_KEY || ''),
  gemini: new GeminiBackend(
    process.env.GCP_PROJECT_ID || '',
    process.env.GCP_LOCATION || '',
    process.env.GCP_ACCESS_TOKEN || ''
  )
};

// â”€â”€ ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ & å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«åã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚° â”€â”€
const modelMap: ModelMap = {
  llama2: { backend: 'openai', model: 'gpt-4' },
  codellama: { backend: 'gemini', model: 'chat-bison@001' },
};

// ãƒ«ãƒ¼ãƒˆã®å®šç¾©
app.post('/api/generate', handleGenerate(backends, modelMap));
app.post('/api/chat', handleChat(backends, modelMap));
app.post('/api/create', (req: Request, res: Response) => {
  res.status(501).json({ error: 'Not implemented' });
});

// ãƒ¢ãƒ‡ãƒ«é–¢é€£ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.get('/api/models', handleListModels(backends, modelMap));
app.post('/api/models/:model', handleModelOperation(backends, modelMap));
app.post('/api/models/:model/copy', handleModelCopy(backends, modelMap));
app.delete('/api/models/:model', handleModelDelete(backends, modelMap));
app.get('/api/tags', handleModelTags(modelMap));  // è¿½åŠ 
app.post('/api/show', handleModelShow(backends, modelMap));  // è¿½åŠ 

// ãã®ä»–ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.post('/api/pull', (req: Request, res: Response) => {
  res.status(501).json({ error: 'Not implemented' });
});

app.post('/api/push', (req: Request, res: Response) => {
  res.status(501).json({ error: 'Not implemented' });
});

app.post('/api/embeddings', (req: Request, res: Response) => {
  res.status(501).json({ error: 'Not implemented' });
});

app.get('/api/ps', (req: Request, res: Response) => {
  res.status(501).json({ error: 'Not implemented' });
});

app.get('/api/version', (req: Request, res: Response) => {
  res.status(501).json({ error: 'Not implemented' });
});

// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
app.use((err: Error, req: Request, res: Response, next: NextFunction) => {
  console.error(err);
  const error = err as AxiosError;
  const status = error.response?.status || 500;
  const data = error.response?.data || error.message || 'Unknown error';
  res.status(status).json({ error: data });
});

const PORT = process.env.PORT || 11434;
app.listen(PORT, () => {
  console.log(`Ollama ãƒ—ãƒ­ãƒˆã‚³ãƒ«äº’æ›ã‚µãƒ¼ãƒãƒ¼ (stubs) running on port ${PORT}`);
});
